# Displaced Vertex Recasting #

## Authors: ##
[Andre Lessa](mailto:andre.lessa@ufabc.edu.br)

This repository holds the main code for recasting the 13 TeV ATLAS search for displaced vertices
 ([ATLAS-SUSY-2018-13](https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/SUSY-2018-13/))
using the efficiency grids  for event and vertex reconstruction selection provided [here](https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/SUSY-2018-13/hepdata_info.pdf).

## Pre-Requisites and Installation ##

The following pre-requisites must be installed before compiling the main code:

  * [MadGraph5](https://launchpad.net/mg5amcnlo/)
  * [Delphes](https://cp3.irmp.ucl.ac.be/projects/delphes)[^1]
  * [Pythia8](https://pythia.org/)
  * [HepMC](http://hepmc.web.cern.ch/hepmc/)

Running:

```
./installer.sh
```

Will try to fetch the required packages and install them in the current folder.
*Note that a modified version of Delphes should be installed using [../../Delphes_LLP/DelphesLLP.tar.gz](../../Delphes_LLP/DelphesLLP.tar.gz)*
The LHAPDF, Pythia8 and Delphes directories must be included in the library and root include paths.
This can be done running:

```
source setenv.sh
```

## Running ##

The recasting is based on the Delphes output generated by running MadGraph/Pythia/Delphes.
Note that the Delphes card must define the PDG codes for the LLPs in the LLPFilter block, so the relevant information is stored in the Delphes output. An example can be found [here](./validation/Cards/chargino/delphes_card_chargino).


The event yields and recasting info can then be obtained running:

```
usage: atlas_susy_2018_13_Recast.py [-h] -f INPUTFILE [INPUTFILE ...] [-o OUTPUTFILE] [-n] [-m MODEL] [-v VERBOSE]


options:
  -h, --help            show this help message and exit
  -f INPUTFILE [INPUTFILE ...], --inputFile INPUTFILE [INPUTFILE ...]
                        path to the ROOT event file(s) generated by Delphes.
  -o OUTPUTFILE, --outputFile OUTPUTFILE
                        path to output file storing the DataFrame with the recasting data. If not defined, will use the name of the first input file
  -n, --normalize       If set, the input files will be considered to refer to multiple samples of the same process and their weights will be normalized.
  -m MODEL, --model MODEL
                        Defines which model should be considered for extracting model parameters (strong,ewk,gluino).
  -v VERBOSE, --verbose VERBOSE
                        verbose level (debug, info, warning or error). Default is info

```

where model is used to fetch the relevant model parameters depending on the scenario (stau, wino or gluino).
This information is used only for conveniently storing the model parameters (such as the proper lifetime) along with the recasting info.
The user can easily modify the [helper.py](./helper.py) code for other models.
The output is a pickle file containing a Pandas DataFrame with the model parameters and recasting output.


For combining results from multiple model points into a single DataFrame, run:

```
./atlas_susy_2018_13_CombineData.py -f <pickle file1> <pickle file2> ... -o <output file>
```

Finally, for computing upper limits:

```
./atlas_susy_2018_13_UpperLimits.py -f <pickle file>  -o <output file>
```

The result is again a DataFrame, but now including an upper limit column.



## Validation

The validation of the recasting code was done using the Wino (Chargino), Stau and Gluino benchmarks considered by ATLAS.

The scan over the parameter space can be conveniently done running:

```
./runScanMG5.py -p <parameters file>
```
where basic required input is defined [parameter file](./validation/scan_parameters_chargino.ini) specifying the input cards and model parameters.
The output is a Delphes ROOT file for each model point.

The MadGraph, Pythia and Delphes cards for each scenario can be found in [./validation/Cards](./validation/Cards/).
The recasting results and plotting scripts can be found in the folders: [chargino_results](./validation/chargino_results), [stau_results](./validation/stau_results) and [gluino_results](./validation/gluino_results).

## Validation ##

### Electroweak Scenario

 Below we show the cut-flow comparison for electroweak production: values correspond to Recast (ATLAS) acceptance and final acceptance times efficiency.

|                              |               |               |               |               |
|:-----------------------------|:--------------|:--------------|:--------------|:--------------|
| $m_{\tilde \chi_1^0} (GeV)$  | 500.0         | 500.0         | 1300.0        | 1300.0        |
| $\tau(\tilde \chi_1^0) (ns)$ | 0.1           | 1.0           | 0.1           | 1.0           |
| Total                        | 1.0           | 1.0           | 1.0           | 1.0           |
| Jet selection                | 0.502 (0.495) | 0.513 (0.501) | 0.984 (0.968) | 0.986 (0.985) |
| $R_{xy},z <$ 300 mm          | 0.502 (0.495) | 0.416 (0.410) | 0.984 (0.968) | 0.924 (0.921) |
| $R_{DV} > 4$ mm              | 0.465 (0.465) | 0.403 (0.398) | 0.865 (0.859) | 0.905 (0.899) |
| $d_0 > 2$ mm                 | 0.464 (0.465) | 0.402 (0.398) | 0.863 (0.859) | 0.905 (0.899) |
| $nTracks >= 5$               | 0.464 (0.465) | 0.402 (0.398) | 0.863 (0.859) | 0.905 (0.899) |
| mDV > 10 GeV                 | 0.464 (0.465) | 0.402 (0.398) | 0.863 (0.859) | 0.905 (0.899) |
| final Acc*Eff                | 0.288 (0.311) | 0.142 (0.143) | 0.104 (0.122) | 0.080 (0.083) |


A comparison between the official ATLAS 95\% C.L. exclusion curve for the wino scenario and the one obtained using this recasting code is shown below:


![Alt text](validation/chargino_results/chargino_fig17a.png?raw=true "Chargino Validation Plot")

Validation of the acceptances and efficiencies for all the benchmark points can be found in [this notebook](./validation/chargino_results/validation_CharginoTables.ipynb)

### Strong Scenario


 Below we show the cut-flow comparison for strong production: values correspond to Recast (ATLAS) acceptance and final acceptance times efficiency.


|                              |               |               |               |               |
|:-----------------------------|:--------------|:--------------|:--------------|:--------------|
| $m_{\tilde g} (GeV)$         | 2000.0        | 2000.0        | 2400.0        | 2000.0        |
| $m_{\tilde \chi_1^0} (GeV)$  | 850.0         | 50.0          | 200.0         | 1250.0        |
| $\tau(\tilde \chi_1^0) (ns)$ | 0.01          | 0.1           | 1.0           | 10.0          |
| Total                        | 1.0           | 1.0           | 1.0           | 1.0           |
| Jet selection                | 0.999 (0.999) | 0.967 (0.966) | 0.985 (0.972) | 0.999 (0.961) |
| $R_{xy},z <$ 300 mm          | 0.999 (0.999) | 0.788 (0.787) | 0.442 (0.447) | 0.311 (0.317) |
| $R_{DV} > 4$ mm              | 0.298 (0.296) | 0.772 (0.770) | 0.434 (0.438) | 0.304 (0.309) |
| $d_0 > 2$ mm                 | 0.296 (0.296) | 0.767 (0.756) | 0.433 (0.437) | 0.304 (0.309) |
| $nTracks >= 5$               | 0.296 (0.296) | 0.766 (0.755) | 0.433 (0.437) | 0.304 (0.309) |
| mDV > 10 GeV                 | 0.296 (0.296) | 0.760 (0.747) | 0.433 (0.437) | 0.304 (0.309) |
| final Acc*Eff                | 0.274 (0.278) | 0.140 (0.144) | 0.112 (0.115) | 0.090 (0.092) |


A comparison between the official ATLAS 95\% C.L. exclusion curve for the stau scenario and the one obtained using this recasting code is shown below:


![Alt text](validation/stau_results/stau_fig17b.png?raw=true "Stau Validation Plot")

Validation of the acceptances and efficiencies for all the benchmark points can be found in [this notebook](./validation/stau_results/validation_StauTables.ipynb)


[^1]: A modified version of Delphes needs to be installed, which includes a module for filtering LLPs
      and storing their decays.  


