{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ATLAS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauDict = {'deltaM30': {0.3 : (9,56), 1.0 : (26,42), 3.0 : (43,28), 10.0 : (60,14), 30.0 : (77,0)},\n",
    "           'm100' : {0.3 : (9,100), 1.0 : (32,80), 3.0 : (55,60), 10.0 : (78,40), 30.0 : (101,20)}\n",
    "         }\n",
    "           \n",
    "\n",
    "dfs = []\n",
    "files = {'deltaM30' : './HEPData-ins2080541-v1-csv/Acceptance,R-hadron,compressed.csv',\n",
    "         'm100' : './HEPData-ins2080541-v1-csv/Acceptance,R-hadron.csv'}\n",
    "for tag in tauDict:\n",
    "    for tau,(skip_header,skip_footer) in tauDict[tag].items():\n",
    "        deltaM30 = np.genfromtxt(files[tag],skip_header=skip_header,delimiter=',',names=True,skip_footer=skip_footer)\n",
    "        newDF = pd.DataFrame.from_dict({'mLLP' : deltaM30['Mass_GeV']})\n",
    "        if tag == 'deltaM30':\n",
    "            newDF['mLSP'] = newDF['mLLP']-30.0\n",
    "        else:\n",
    "            newDF['mLSP'] = 100.0\n",
    "        newDF['Acceptance'] = deltaM30['Acceptance']\n",
    "        newDF['tau_ns'] = tau\n",
    "        dfs.append(newDF)\n",
    "\n",
    "atlasAccDF = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Level Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "files = {'deltaM30' : './HEPData-ins2080541-v1-csv/Event-levelefficiency,R-hadron,compressed.csv',\n",
    "         'm100' : './HEPData-ins2080541-v1-csv/Event-levelefficiency,R-hadron.csv'}\n",
    "for tag in tauDict:\n",
    "    for tau,(skip_header,skip_footer) in tauDict[tag].items():\n",
    "        deltaM30 = np.genfromtxt(files[tag],skip_header=skip_header,delimiter=',',names=True,skip_footer=skip_footer)\n",
    "        newDF = pd.DataFrame.from_dict({'mLLP' : deltaM30['Mass_GeV']})\n",
    "        if tag == 'deltaM30':\n",
    "            newDF['mLSP'] = newDF['mLLP']-30.0\n",
    "        else:\n",
    "            newDF['mLSP'] = 100.0\n",
    "        newDF['Event Efficiency'] = deltaM30['Eventlevel_Efficiency']\n",
    "        newDF['tau_ns'] = tau\n",
    "        dfs.append(newDF)\n",
    "\n",
    "atlasEvtEffDF = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SR Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlasSRs = []\n",
    "for sr in ['Inclusive_Low','Inclusive_High']:\n",
    "    sr_tag = sr.split('_')[1]\n",
    "    dfs = []\n",
    "    files = {'deltaM30' : './HEPData-ins2080541-v1-csv/Efficiency,SR-%s,R-hadron,compressed.csv'%sr,\n",
    "            'm100' : './HEPData-ins2080541-v1-csv/Efficiency,SR-%s,R-hadron.csv'%sr}\n",
    "    for tag in tauDict:\n",
    "        for tau,(skip_header,skip_footer) in tauDict[tag].items():\n",
    "            deltaM30 = np.genfromtxt(files[tag],skip_header=skip_header,delimiter=',',names=True,skip_footer=skip_footer)\n",
    "            newDF = pd.DataFrame.from_dict({'mLLP' : deltaM30['Mass_GeV']})\n",
    "            if tag == 'deltaM30':\n",
    "                newDF['mLSP'] = newDF['mLLP']-30.0\n",
    "            else:\n",
    "                newDF['mLSP'] = 100.0\n",
    "            newDF['(SR-%s - no mass Window)' %sr_tag] = deltaM30['Efficiency_%s' %sr]\n",
    "            newDF['tau_ns'] = tau\n",
    "            dfs.append(newDF)\n",
    "\n",
    "    atlasSRs.append(pd.concat(dfs, ignore_index=True))\n",
    "atlasSREffDF = pd.merge(*atlasSRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlasDF = pd.merge(atlasAccDF, atlasEvtEffDF,how='inner')\n",
    "atlasDF = pd.merge(atlasDF, atlasSREffDF,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderColumns = ['mLLP','mLSP','tau_ns']\n",
    "atlasDF.sort_values(orderColumns,inplace=True,\n",
    "                ascending=[True,True,True],ignore_index=True)\n",
    "res = atlasDF.reindex(columns=orderColumns+[c for c in atlasDF.columns if c not in orderColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlasDF.to_pickle('gluinoTables.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
