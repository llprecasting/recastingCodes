{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "import sys,os,glob,copy\n",
    "import numpy as np\n",
    "import pyslha\n",
    "import ROOT\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d,griddata,LinearNDInterpolator\n",
    "\n",
    "ROOT.gSystem.Load(os.path.abspath(\"./MG5/Delphes/libDelphes.so\"))\n",
    "\n",
    "try:\n",
    "    ROOT.gInterpreter.Declare('#include \"classes/SortableObject.h\"')\n",
    "    ROOT.gInterpreter.Declare('#include \"classes/DelphesClasses.h\"')\n",
    "    ROOT.gInterpreter.Declare('#include \"external/ExRootAnalysis/ExRootTreeReader.h\"')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "\n",
    "plt.rcParams.update({\"savefig.dpi\" : 300}) #Figure resolution\n",
    "\n",
    "\n",
    "#Define plotting style:\n",
    "sns.set() #Set style\n",
    "sns.set_style('ticks',{'font.family':'Times New Roman', 'font.serif':'Times New Roman'})\n",
    "sns.set_context('paper', font_scale=1.8)\n",
    "cm = plt.cm.get_cmap('RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = './recastCode/ATLAS_data/HEPData-ins2080541-v1-csv/MuonReconstructionEfficiencydistribution.csv'\n",
    "gridPtsReco = np.genfromtxt(inputFile,names=True,skip_header=7,delimiter=',')\n",
    "muonEff_F = LinearNDInterpolator((gridPtsReco['beta'],gridPtsReco['eta']),gridPtsReco['Efficiency'],fill_value=0.0)\n",
    "\n",
    "inputFile = './recastCode/ATLAS_data/HEPData-ins2080541-v1-csv/TriggerEfficiencydistribution.csv'\n",
    "gridPtsTrig = np.genfromtxt(inputFile,names=True,skip_header=7,delimiter=',')\n",
    "triggerEff_F = interp1d(gridPtsTrig['Truth_Level_ETmiss_calo_GeV'],gridPtsTrig['Efficiency'],\n",
    "                      fill_value=0.0,bounds_error=False)\n",
    "\n",
    "inputFile = './recastCode/ATLAS_data/HEPData-ins2080541-v1-csv/EventSelectionEfficiencydistribution.csv'\n",
    "gridPtsSel = np.genfromtxt(inputFile,names=True,skip_header=7,delimiter=',')\n",
    "selectionEff_F = interp1d(gridPtsSel['Truth_Level_ETmiss_Total_GeV'],gridPtsSel['Efficiency'],\n",
    "                      fill_value=0.0,bounds_error=False)\n",
    "\n",
    "inputFile = './recastCode/ATLAS_data/HEPData-ins2080541-v1-csv/TrackSelectionEfficiencydistribution.csv'\n",
    "gridPtsHigh = np.genfromtxt(inputFile,names=True,skip_header=34,delimiter=',')\n",
    "trackEffHigh_F = interp1d(gridPtsHigh['beta__gamma'],gridPtsHigh['Efficiency'],\n",
    "                      fill_value=0.0,bounds_error=False)\n",
    "gridPtsLow = np.genfromtxt(inputFile,names=True,skip_header=8,skip_footer=32-8,delimiter=',')\n",
    "trackEffLow_F = interp1d(gridPtsLow['beta__gamma'],gridPtsLow['Efficiency'],\n",
    "                      fill_value=0.0,bounds_error=False)\n",
    "\n",
    "\n",
    "\n",
    "def getMuonRecoEff(beta,eta,pid=None):\n",
    "    \"\"\"\n",
    "    Return the interpolated muon reconstruction efficiency\n",
    "    as a function of beta and eta. If the pid is \n",
    "    \n",
    "    :param beta: HSCP beta\n",
    "    :param eta: HSCP eta\n",
    "    \n",
    "    :return: Efficiency\n",
    "    \"\"\"\n",
    "    \n",
    "    eta = abs(eta)\n",
    "    \n",
    "    eff = muonEff_F(beta,eta)\n",
    "    \n",
    "    return float(eff)\n",
    "    \n",
    "\n",
    "def getTriggerEff(metCalo):\n",
    "    \n",
    "    if metCalo > 1000.:\n",
    "        return 1.0\n",
    "    eff = triggerEff_F(metCalo)\n",
    "    return float(eff)\n",
    "\n",
    "\n",
    "def getSelectionEff(met):\n",
    "    \n",
    "    if met > 1000.:\n",
    "        return 1.0\n",
    "    eff = selectionEff_F(met)\n",
    "    return float(eff)\n",
    "\n",
    "def getTrackEff(gbeta,sr):\n",
    "    \n",
    "    if sr.lower() == 'high':\n",
    "        eff = trackEffHigh_F(gbeta)\n",
    "    elif sr.lower() == 'low':\n",
    "        eff = trackEffLow_F(gbeta)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return float(eff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbetaVals = np.linspace(0.,3.,1000)\n",
    "# eff = [getTrackEff(x,sr='low') for x in gbetaVals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(gbetaVals,eff)\n",
    "# plt.scatter(gridPtsLow['beta__gamma'],gridPtsLow['Efficiency'])\n",
    "# plt.yscale('log')\n",
    "# # plt.ylim(0,1e-3)\n",
    "# # plt.xlim(0,100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pyslha.readSLHAFile('./pp2C1C1/Cards/param_card.dat')\n",
    "mLLP = parameters.blocks['MASS'][1000024]\n",
    "mDM = parameters.blocks['MASS'][1000022]\n",
    "width = parameters.decays[1000024].totalwidth\n",
    "if width:\n",
    "    tau_ns = (6.582e-25/width)*1e9\n",
    "else:\n",
    "    tau_ns = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFiles = {'stable' : './pp2C1C1/Events/run_02/chargino_delphes_events.root',\n",
    "              'prompt' : './pp2C1C1/Events/run_03/prompt_delphes_events.root'}\n",
    "xsecsPB = {'stable' : 7.133e-3, 'prompt' : 7.133e-3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over events, apply basic selection criterium and compute masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weight =  355.90219777077436\n",
      "SR= {'High': 0.28915631553555915, 'Low': 2.0855278872503407}\n"
     ]
    }
   ],
   "source": [
    "weightsDict = {}\n",
    "massesDict = {}\n",
    "sr\n",
    "\n",
    "for label,inputFile in inputFiles.items():\n",
    "\n",
    "    f = ROOT.TFile(inputFile,'read')\n",
    "    tree = f.Get(\"Delphes\")\n",
    "    nevts = tree.GetEntries()\n",
    "    \n",
    "    totalWeight = 0.0\n",
    "    totalWeight60 = 0.0\n",
    "    srWeights = {'High': 0.0, 'Low' : 0.0}\n",
    "\n",
    "    weights = []\n",
    "    masses = []\n",
    "    for ievt in range(nevts):\n",
    "        tree.GetEntry(ievt)\n",
    "        weight = tree.Weight.At(0).Weight\n",
    "        totalWeight += weight\n",
    "        met = tree.MissingET.At(0).MET\n",
    "        metCalo = tree.MissingETCalo.At(0).MET\n",
    "        hscps = []\n",
    "        for iptc in range(tree.Particle.GetEntries()):\n",
    "            particle = tree.Particle.At(iptc)\n",
    "            # Get HSCP\n",
    "            if abs(particle.Charge) != 1: # Skip neutral particles\n",
    "                continue\n",
    "            if particle.Mass < 20.: # Skip light (SM) particles\n",
    "                continue\n",
    "            if particle.Status != 1: # If HSCP is unstable check if it is the last step\n",
    "                d1 = particle.D1\n",
    "                d2 = particle.D2\n",
    "                daughters = [tree.Particle.At(d) for d in range(d1,d2+1)]\n",
    "                if any(daughter.PID == particle.PID for daughter in daughters):\n",
    "                    continue\n",
    "                # Get the HSCP decay radius from the first daughter production vertex:\n",
    "                r_decay = np.sqrt(daugthers[0].X**2 +daugthers[0].Y**2)\n",
    "                particle.r_decay = r_decay\n",
    "            else:\n",
    "                particle.r_decay = np.inf\n",
    "            hscps.append(particle)\n",
    "            \n",
    "        # Get HSCPs pT\n",
    "        px = sum([hscp.Px for hscp in hscps])\n",
    "        py = sum([hscp.Py for hscp in hscps])\n",
    "        hscpPT = np.sqrt(px**2 + py**2)\n",
    "        if hscpPT > 60.:\n",
    "            totalWeight60 += weight\n",
    "        \n",
    "        muonsLLP = []\n",
    "        # Get probability of tagging the HSCP as muon:\n",
    "        for hscp in hscps:\n",
    "            if hscp.r_decay < 1e4: # Skip decays before MS\n",
    "                continue\n",
    "            beta = np.sqrt(hscp.Px**2 +hscp.Py**2 + hscp.Pz**2)/hscp.E\n",
    "            eta = abs(hscp.Eta)\n",
    "            eff = getMuonRecoEff(beta,eta,hscp.PID)\n",
    "            # Randomly reconstrunct the HSCP as a muon\n",
    "            if np.random.uniform() > eff:\n",
    "                continue\n",
    "            muonsLLP.append(hscp)\n",
    "        \n",
    "        if muonsLLP:\n",
    "            # Remove LLPs reconstructed as muons from the hscp list:\n",
    "            hscps = [hscp for hscp in hscps if hscp not in muonsLLP]\n",
    "            # Remove muonsLLp from MET:            \n",
    "            pxTot = sum([m.Px for m in muonsLLP])\n",
    "            pyTot = sum([m.Py for m in muonsLLP])\n",
    "            metx = met*np.cos(tree.MissingET.At(0).Phi)\n",
    "            mety = met*np.sin(tree.MissingET.At(0).Phi)\n",
    "            newMet = np.sqrt((metx-pxTot)**2 + (mety-pyTot)**2)\n",
    "            met = newMet\n",
    "        \n",
    "        if not hscps:\n",
    "            continue\n",
    "        triggerEff = getTriggerEff(metCalo)\n",
    "        eventEff = getSelectionEff(met)\n",
    "        \n",
    "        hscpEffs = {'SR-Inclusive_High' : [], 'SR-Inclusive_Low' : []}\n",
    "        for hscp in hscps:\n",
    "            if hscp.PT < 120.:\n",
    "                continue\n",
    "            if abs(hscp.Eta) > 1.8:\n",
    "                continue\n",
    "            if hscp.r_decay < 500.0:\n",
    "                continue\n",
    "            gbeta = hscp.E/hscp.Mass\n",
    "            trackEffHigh = getTrackEff(gbeta,sr='High')\n",
    "            trackEffLow = getTrackEff(gbeta,sr='Low')\n",
    "            wMassLow = 0.6\n",
    "            wMassHigh = max(0.,0.74 - 0.052*(hscp.Mass/1000.))\n",
    "            hscpEffs['SR-Inclusive_High'].append(trackEffHigh*wMassHigh)\n",
    "            hscpEffs['SR-Inclusive_Low'].append(trackEffLow*wMassLow)\n",
    "            \n",
    "        \n",
    "        # Total event weight\n",
    "        hscpLow = np.array(hscpEffs['SR-Inclusive_Low'])\n",
    "        eventWeightLow = weight*triggerEff*eventEff*(1-np.prod(1.0-hscpLow))\n",
    "\n",
    "        hscpHigh = np.array(hscpEffs['SR-Inclusive_High'])\n",
    "        eventWeightHigh = weight*triggerEff*eventEff*(1-np.prod(1.0-hscpHigh))\n",
    "        \n",
    "        srWeights['Low'] += eventWeightLow\n",
    "        srWeights['High'] += eventWeightHigh\n",
    "\n",
    "    # weights = np.array(weights)\n",
    "    # masses = np.array(masses)\n",
    "    # weightsDict[label] = weights\n",
    "    # massesDict[label] = masses\n",
    "print('Total weight = ',totalWeight)\n",
    "print('SR=',srWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High eff = 0.0008\n",
      "High eff = 0.0019\n",
      "Low eff = 0.0059\n",
      "Low eff = 0.0138\n"
     ]
    }
   ],
   "source": [
    "for sr,eff in srWeights.items():\n",
    "    print('%s eff = %1.4f' %(sr,eff/totalWeight))\n",
    "    print('%s eff = %1.4f' %(sr,eff/totalWeight60))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove failed attempts to reconstruct masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label in massesDict:\n",
    "    oldMasses = massesDict[label]\n",
    "    oldWeights = weightsDict[label]\n",
    "\n",
    "    newMasses = []\n",
    "    newWeights = []\n",
    "    for i,mass in enumerate(oldMasses):\n",
    "        # Remove events where reconstruction failed\n",
    "        if np.any(mass == None): \n",
    "            continue\n",
    "        # Remove events for which parent masses differ more than 5%\n",
    "        if 2*abs(mass[0,0]-mass[1,0])/(mass[0,0]+mass[1,0]) > 0.05: \n",
    "            continue\n",
    "        # Remove events for which parent masses are smaller than daughers        \n",
    "        if (mass[0,0] < mass[0,1]) or (mass[1,0] < mass[1,1]): \n",
    "            continue\n",
    "        newMasses.append(mass)\n",
    "        newWeights.append(oldWeights[i])\n",
    "        \n",
    "    massesDict[label] = np.array(newMasses)\n",
    "    weightsDict[label] = np.array(newWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many events were kept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in massesDict:\n",
    "    f = ROOT.TFile(inputFiles[label],'read')\n",
    "    tree = f.Get(\"Delphes\")\n",
    "    nevts = tree.GetEntries()\n",
    "    kept = len(massesDict[label])\n",
    "    print('\\n%s: Kept %i events out of %i' %(label,kept,nevts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "colorsDict = dict(zip(massesDict.keys(),sns.color_palette(\"Paired\")[:len(massesDict)]))\n",
    "lineDict = dict(zip(massesDict.keys(),['-','--']))\n",
    "\n",
    "for label in massesDict:\n",
    "    m = massesDict[label]\n",
    "    \n",
    "    motherMasses = np.concatenate((m[:,0,0],m[:,1,0]))\n",
    "    daughterMasses = np.concatenate((m[:,0,1],m[:,1,1]))\n",
    "\n",
    "\n",
    "    plt.hist(motherMasses,bins=np.arange(0,600.,10.),\n",
    "             histtype='step',label=r'Mother (%s)' %label,\n",
    "             linewidth=2,color=colorsDict[label],linestyle=lineDict[label])\n",
    "    \n",
    "    plt.hist(daughterMasses,bins=np.arange(0,600.,10.),\n",
    "            histtype='step',label=r'Daughter (%s)' %label,\n",
    "            linewidth=2,color=colorsDict[label],linestyle=lineDict[label])\n",
    "\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.xlabel(r'$M_X$ (GeV)')\n",
    "plt.ylabel('Events')\n",
    "plt.legend(loc=(0.9,0.6),framealpha=1.0)\n",
    "plt.title(r'$M_{F} = %1.0f$ GeV, $M_{s} = %1.0f$ GeV, $\\lambda_{3} = %1.1f$'\n",
    "          %(mF,mDM,ls3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = 3000e3 # luminosity in 1/pb\n",
    "lsEff = 4*mDM\n",
    "\n",
    "allProcessesM = []\n",
    "allProcessesD = []\n",
    "allProcessesW = []\n",
    "allProcessesL = []\n",
    "for label in massesDict:\n",
    "    m = massesDict[label]\n",
    "    w = weightsDict[label]\n",
    "    \n",
    "    motherMasses = np.concatenate((m[:,0,0],m[:,1,0]))\n",
    "    daughterMasses = np.concatenate((m[:,0,1],m[:,1,1]))\n",
    "    weights = ((lsEff/ls3)**2)*np.concatenate((w,w))*lumi # Rescale weights by new lambda3 value\n",
    "\n",
    "    allProcessesM.append(motherMasses)\n",
    "    allProcessesD.append(daughterMasses)\n",
    "    allProcessesW.append(weights)\n",
    "    allProcessesL.append(label)\n",
    "    \n",
    "plt.figure(figsize=(10,5))\n",
    "label = 'Mother (' +','.join(allProcessesL) +')'\n",
    "color = [colorsDict[l] for l in allProcessesL]\n",
    "bins = plt.hist(allProcessesM,bins=np.arange(0,600.,10.),histtype='bar',stacked=True,\n",
    "                label=label,linewidth=2,\n",
    "                weights=allProcessesW,color=color)\n",
    "\n",
    "label = 'Daughter (' +','.join(allProcessesL) +')'\n",
    "bins = plt.hist(allProcessesD,bins=np.arange(0,600.,10.),histtype='bar',stacked=True,\n",
    "                label=label,linewidth=2,\n",
    "                weights=allProcessesW,color=color)\n",
    "\n",
    "\n",
    "ymax = bins[0].flatten().max()    \n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.ylim(1,2*ymax)\n",
    "plt.xlabel(r'$M_X$ (GeV)')\n",
    "plt.ylabel('Events')\n",
    "plt.legend(loc=(0.9,0.6),framealpha=1.0)\n",
    "plt.title(r'$M_{F} = %1.0f$ GeV, $M_{s} = %1.0f$ GeV, $\\lambda_{3} = %1.1f$ GeV, $\\mathcal{L} = %1.0f \\mbox{ fb}^{-1}$' %(mF,mDM,lsEff,lumi/1e3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
